{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "hdf5 = require 'hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "* Filter windows of height $h$ are applied in sizes of $3,4,5$ with TODO feature\n",
    "maps. Specifically the filters are applied as a matrix $W \\in \\mathbb{R}^{h \\times k}$\n",
    "to a window of size $h \\times k$.\n",
    "* The stride of the filters is $1$ to iterate over all possible windows of words\n",
    "(*narrow convolution*).\n",
    "* A dropout of rate $\\rho = .5$ is applied at training time to prevent overfitting.\n",
    "* An $l_2$ constraint $s = 3$ is applied in (Kim, 2014). However (Zhang and Wallace, 2015)\n",
    "found that this constraint had little effect on the performance of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- metadata\n",
    "epochs = 4\n",
    "classes = {'1', '2', '3', '4', '5', '6', '7', '8'}\n",
    "sent_len = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Input format is a matrix $M \\in \\mathbb{R}^{n} \\times k$\n",
    "with:\n",
    "* $n$ number of words in the document\n",
    "* $k$ the dimension of the word vectors obtained from word2vec\n",
    "* the data is zero-padded to the length of the longest document\n",
    "(alternatively to a given maximum length). All not-taken word spaces\n",
    "are set to zero in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_kth_partition(k)\n",
    "    fname = \"../data/prepped_train_X_word2vec_wordvecs_\"..k..\".h5\"\n",
    "    print(\"retrieving \"..fname)\n",
    "    file = hdf5.open(fname, 'r')\n",
    "    data = file:read():all()\n",
    "    file:close()\n",
    "\n",
    "    return data[\"dataset_\"..k..\"_x_train\"]\n",
    "        , data[\"dataset_\"..k..\"_y_train\"]\n",
    "        , data[\"dataset_\"..k..\"_x_test\"]\n",
    "        , data[\"dataset_\"..k..\"_y_test\"]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- FIXME: replace this with something better\n",
    "function copy_example(example)\n",
    "    local X_i = torch.Tensor(6, sent_len, example:size()[2]):zero()\n",
    "\n",
    "    for j = 1, example:size()[1] do\n",
    "        X_i[{1, j}] = example[j]\n",
    "        X_i[{2, j}] = example[j]\n",
    "        X_i[{3, j}] = example[j]\n",
    "        X_i[{4, j}] = example[j]\n",
    "        X_i[{5, j}] = example[j]\n",
    "        X_i[{6, j}] = example[j]\n",
    "    end\n",
    "\n",
    "    return X_i\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- binarize label probabilities\n",
    "function binarize_pred_labels(labels)\n",
    "    bin = torch.Tensor(labels:size()[1])\n",
    "\n",
    "    for i = 1, labels:size()[1] do\n",
    "        if labels[i] > .5 then\n",
    "            bin[i] = 1\n",
    "        else\n",
    "            bin[i] = 0\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return bin\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_model(sent_len, wordvec_len, dropout_rho, l2_constr)\n",
    "    local model = nn.Sequential()\n",
    "    model:add(nn.Identity())\n",
    "\n",
    "    -- stage 1: convolutions\n",
    "\n",
    "    -- in: applies the following declared layers to the first dimension of the\n",
    "    -- tensor (see above.)\n",
    "    --\n",
    "    -- out: concatenating the three concatenated max-pooled values to a vector\n",
    "    -- fed to the fully connected softmax layer yielding the outputs\n",
    "\n",
    "    -- in: tensor of 6 x num_exaples x sent_len x wordvec_len\n",
    "    --p = nn.ConcatTable()\n",
    "    local p = nn.Parallel(1,1)\n",
    "\n",
    "    -- this is a convolution unit differing in the height of the filter being\n",
    "    -- applied. each filter is used double time to further improve performance.\n",
    "    -- each filter yields a feature map, thus for each region size we then\n",
    "    -- have two feature maps, and in total then six (if using default n-grams\n",
    "    -- 3 to 5 like (Kim, 2014))\n",
    "    for i = 3, 5 do\n",
    "        -- elements of the convolution\n",
    "        local s1 = nn.Sequential()\n",
    "        local s2 = nn.Sequential()\n",
    "\n",
    "        -- input: sent_len x wordvec_len\n",
    "        s1:add(nn.Reshape(1, sent_len, wordvec_len))\n",
    "        s2:add(nn.Reshape(1, sent_len, wordvec_len))\n",
    "\n",
    "        -- takes size of input plane (we only have one channel though)\n",
    "        -- as well as output plane (again, using only one channel)\n",
    "        -- kernel width and kernel height as third and fourth arguments\n",
    "\n",
    "        -- in: 1 x sent_len x wordvec_len\n",
    "        -- args: input channels, output channels, kernel width, kernel height\n",
    "        s1:add(nn.SpatialConvolution(1, 1, wordvec_len, i))\n",
    "        s2:add(nn.SpatialConvolution(1, 1, wordvec_len, i))\n",
    "        -- out: sent_len - filter_height + 1\n",
    "\n",
    "        -- non-linearities\n",
    "        -- in: sent_len - filter_height + 1\n",
    "        s1:add(nn.ReLU())\n",
    "        s2:add(nn.ReLU())\n",
    "        -- out: sent_len - filter_height + 1\n",
    "\n",
    "        -- the viewed region of the matrix for max-pooling shall be the\n",
    "        -- size of the matrix, as we want all values to be considered at\n",
    "        -- once for a single maximum for each filter map.\n",
    "        -- in: sent_len - filter_height + 1\n",
    "        s1:add(nn.SpatialMaxPooling(1, sent_len - i + 1))\n",
    "        s2:add(nn.SpatialMaxPooling(1, sent_len - i + 1))\n",
    "        -- out: scalar\n",
    "\n",
    "        p:add(s1)\n",
    "        p:add(s2)\n",
    "    end\n",
    "\n",
    "    model:add(p)\n",
    "\n",
    "    -- [6x1x1] -> [1x6]\n",
    "    model:add(nn.View(1,6))\n",
    "\n",
    "    -- stage 2: fully connected softmax layer\n",
    "    model:add(nn.Normalize(2, l2_constr))\n",
    "    model:add(nn.Dropout(dropout_rho))\n",
    "    model:add(nn.Linear(6, 8))\n",
    "\n",
    "    --model:add(nn.LogSoftMax()) -- for ClassNLLCriterion\n",
    "    model:add(nn.Sigmoid())\n",
    "\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train(model, criterion, batch_size, X_k, Y_k)\n",
    "    local no_examples = X_k:size()[1]\n",
    "    local parameters, grad_parameters = model:getParameters()\n",
    "    model:training()\n",
    "    local tic = os.clock()\n",
    "\n",
    "    print(\"training network\")\n",
    "\n",
    "    local next_batch = function(offset, inputs, targets)\n",
    "        end_offset = offset + batch_size - 1\n",
    "\n",
    "        -- calculate size of remaining items if we have less than\n",
    "        -- batch_size examples left.\n",
    "        if end_offset > inputs:size()[1] then\n",
    "            end_offset = offset + (inputs:size()[1] - offset)\n",
    "        end\n",
    "\n",
    "        print(\"getting \"..offset..\" to \"..end_offset..\" of \"..inputs:size()[1])\n",
    "\n",
    "        return inputs[{{offset, end_offset}, {}, {}}], targets[{{offset, end_offset}, {}}]\n",
    "    end\n",
    "\n",
    "    for i = 1, no_examples, batch_size do\n",
    "        inputs, targets = next_batch(i, X_k, Y_k)\n",
    "        num_inputs = inputs:size()[1]\n",
    "\n",
    "        local feval = function(x)\n",
    "            if x ~= parameters then\n",
    "                parameters:copy(x)\n",
    "            end\n",
    "\n",
    "            grad_parameters:zero()\n",
    "\n",
    "            local f = 0\n",
    "            for i = 1, num_inputs do\n",
    "                local X_k_i = copy_example(inputs[i])\n",
    "                local output = model:forward(X_k_i):reshape(8)\n",
    "                local bin_output = binarize_pred_labels(output)\n",
    "                local targets_i = targets[i]:type(\"torch.DoubleTensor\")\n",
    "\n",
    "                local err = criterion:forward(output, targets_i)\n",
    "                f = f + err\n",
    "\n",
    "                local df_do = criterion:backward(bin_output, targets_i)\n",
    "                model:backward(inputs[i], df_do)\n",
    "            end\n",
    "\n",
    "            grad_parameters:div(num_inputs)\n",
    "            f = f / num_inputs\n",
    "\n",
    "            return f, grad_parameters\n",
    "        end\n",
    "\n",
    "        optim.adadelta(feval, parameters, {})\n",
    "    end\n",
    "\n",
    "    print(\"done.\")\n",
    "    local toc = os.clock() - tic\n",
    "    print(\"took \"..toc..\"s\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function evaluate(model, inputs, targets)\n",
    "    local c = torch.Tensor(8, 4):zero()\n",
    "\n",
    "    local preds = {}\n",
    "    model:evaluate()\n",
    "\n",
    "    -- check for TN, TP, FN, FP\n",
    "    for i = 1, inputs:size()[1] do\n",
    "        local prediction = model:forward(copy_example(inputs[i])):reshape(8)\n",
    "        preds[#preds + 1] = prediction\n",
    "\n",
    "        for j = 1, 8 do\n",
    "            if torch.ceil(prediction[j]) ~= targets[i][j] then\n",
    "                if prediction[j] >= .5 and targets[i][j] <= .5 then\n",
    "                    -- false positive\n",
    "                    c[j][3] = c[j][3] + 1\n",
    "                else\n",
    "                    -- false negative\n",
    "                    c[j][4] = c[j][4] + 1\n",
    "                end\n",
    "            else\n",
    "                if prediction[j] >= .5 then\n",
    "                    -- true positive\n",
    "                    c[j][1] = c[j][1] + 1\n",
    "                else\n",
    "                    -- true negative\n",
    "                    c[j][2] = c[j][2] + 1\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return c, preds\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retrieving ../data/prepped_train_X_word2vec_wordvecs_0.h5\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training epoch 1\t\n",
       "training network\t\n",
       "getting 1 to 100 of 1930\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusions = {}\n",
    "predictions = {}\n",
    "\n",
    "for k = 1, 10 do\n",
    "    local criterion = nn.BCECriterion()\n",
    "    local model = get_model(150, 300, .5, 3)\n",
    "    local x_train, y_train, x_test, y_test = get_kth_partition(k-1)\n",
    "\n",
    "    for e = 1, epochs do\n",
    "        print(\"training epoch \"..e)\n",
    "        -- train with batch_size = 100\n",
    "        train(model, criterion, 100, x_train, y_train)\n",
    "    end\n",
    "\n",
    "    local c, preds = evaluate(model, x_test, y_test)\n",
    "    predictions[k] = preds\n",
    "    confusions[k] = c\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "-- evaluating confusion \"matrices\". not real ones but class-wise TP, TN, FP, FN\n",
    "-- for each of the k partitioned datasets.\n",
    "-- now we need to calculate macro/micro F1/R/P\n",
    "local P_micro_aggr = 0\n",
    "local R_micro_aggr = 0\n",
    "local P_macro_aggr = 0\n",
    "local R_macro_aggr = 0\n",
    "\n",
    "-- the metrics are evaluated for each dataset.\n",
    "-- the micro averaging is calculated on the cumulative tp/fp/fn\n",
    "-- for a class while the macro averaging calculates the metric\n",
    "-- for each class, sums these up and divides them by the class\n",
    "-- count\n",
    "\n",
    "for i = 1, #confusions do\n",
    "    print('set '..i)\n",
    "    local P_aggr = 0\n",
    "    local R_aggr = 0\n",
    "    local TP_aggr = 0\n",
    "    local TN_aggr = 0\n",
    "    local FP_aggr = 0\n",
    "    local FN_aggr = 0\n",
    "\n",
    "    -- TP, TN, FP, FN\n",
    "    for j = 1, 8 do\n",
    "        print('class '..j)\n",
    "        local TP_i = confusions[i][j][1]\n",
    "        print('TP '..TP_i)\n",
    "        local TN_i = confusions[i][j][2]\n",
    "        print('TN '..TN_i)\n",
    "        local FP_i = confusions[i][j][3]\n",
    "        print('FP '..FP_i)\n",
    "        local FN_i = confusions[i][j][4]\n",
    "        print('FN '..FN_i)\n",
    "\n",
    "        TP_aggr = TP_aggr + TP_i\n",
    "        TN_aggr = TN_aggr + TN_i\n",
    "        FP_aggr = FP_aggr + FP_i\n",
    "        FN_aggr = FN_aggr + FN_i\n",
    "\n",
    "        -- macro\n",
    "        local P_i = (TP_i + 1) / (TP_i + FP_i + 1)\n",
    "        P_aggr = P_aggr + P_i\n",
    "\n",
    "        local R_i = (TP_i + 1) / (TP_i + FN_i + 1)\n",
    "        R_aggr = R_aggr + R_i\n",
    "    end\n",
    "\n",
    "    print('  P macro: '..(P_aggr / 8))\n",
    "    print('  R macro: '..(R_aggr / 8))\n",
    "    print('  P micro: '..((TP_aggr + 1) / (TP_aggr + FN_aggr + 1)))\n",
    "    print('  R micro: '..((TP_aggr + 1) / (TP_aggr + FP_aggr + 1)))\n",
    "\n",
    "    P_macro_aggr = P_macro_aggr + (P_aggr / 8)\n",
    "    R_macro_aggr = R_macro_aggr + (R_aggr / 8)\n",
    "    R_micro_aggr = R_micro_aggr + ((TP_aggr + 1) / (TP_aggr + FP_aggr + 1))\n",
    "    P_micro_aggr = P_micro_aggr + ((TP_aggr + 1) / (TP_aggr + FN_aggr + 1))\n",
    "end\n",
    "\n",
    "P_macro = P_macro_aggr / #confusions\n",
    "R_macro = R_macro_aggr / #confusions\n",
    "P_micro = P_micro_aggr / #confusions\n",
    "R_micro = R_micro_aggr / #confusions\n",
    "\n",
    "print('P_macro: '..P_macro)\n",
    "print('R_macro: '..R_macro)\n",
    "print('F1_macro: '..((2 * P_macro * R_macro) / (P_macro + R_macro)))\n",
    "print('P_micro: '..P_micro)\n",
    "print('R_micro: '..R_micro)\n",
    "print('F1_micro: '..((2 * P_micro * R_micro) / (P_micro + R_micro)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- 1 epochs\n",
    "-- P_macro: 0.69945066586954\n",
    "-- R_macro: 0.64201492791503\n",
    "-- F1_macro: 0.66950322230995\n",
    "-- P_micro: 0.68537999276845\n",
    "-- R_micro: 0.59231310709299\n",
    "-- F1_micro: 0.63545706414173\n",
    "\n",
    "-- 3 epochs\n",
    "-- P_macro: 0.63519394650611\n",
    "-- R_macro: 0.79737983358683\n",
    "-- F1_macro: 0.70710611962693\n",
    "-- P_micro: 0.81134224534116\n",
    "-- R_micro: 0.60977941734798\n",
    "-- F1_micro: 0.6962666387025\n",
    "\n",
    "-- 4 epochs\n",
    "-- P_macro: 0.62607635104592\n",
    "-- R_macro: 0.82234686224491\n",
    "-- F1_macro: 0.71091365849986\n",
    "-- P_micro: 0.83636380928908\n",
    "-- R_micro: 0.60415084660385\n",
    "-- F1_micro: 0.70154080194013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "* **(Kim, 2014):** Convolutional Neural Networks for Sentence Classification by Yoon Kim\n",
    "* **(Zhang and Wallace, 2015):** A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification by Ye Zhang, Byron Wallace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retrieving ../data/prepped_train_X_word2vec_wordvecs_0.h5\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "training epoch 1\t\n",
       "training network\t\n",
       "getting 1 to 100 of 1930\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "bad argument #2 to '?' (index out of bound at /Users/nexus/torch/pkg/torch/generic/Tensor.c:779)\nstack traceback:\n\t[C]: at 0x1204e140\n\t[C]: in function '__newindex'\n\t[string \"-- FIXME: replace this with something better...\"]:6: in function 'copy_example'\n\t[string \"function train(model, criterion, batch_size, ...\"]:36: in function 'opfunc'\n\t/Users/nexus/torch/install/share/lua/5.1/optim/adadelta.lua:29: in function 'adadelta'\n\t[string \"function train(model, criterion, batch_size, ...\"]:54: in function 'train'\n\t[string \"criterion = nn.BCECriterion()...\"]:8: in main chunk\n\t[C]: in function 'xpcall'\n\t/Users/nexus/torch/install/share/lua/5.1/itorch/main.lua:179: in function </Users/nexus/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t/Users/nexus/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/Users/nexus/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/Users/nexus/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/Users/nexus/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/Users/nexus/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t[string \"arg={'/Users/nexus/.ipython/profile_default/s...\"]:1: in main chunk",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "bad argument #2 to '?' (index out of bound at /Users/nexus/torch/pkg/torch/generic/Tensor.c:779)\nstack traceback:\n\t[C]: at 0x1204e140\n\t[C]: in function '__newindex'\n\t[string \"-- FIXME: replace this with something better...\"]:6: in function 'copy_example'\n\t[string \"function train(model, criterion, batch_size, ...\"]:36: in function 'opfunc'\n\t/Users/nexus/torch/install/share/lua/5.1/optim/adadelta.lua:29: in function 'adadelta'\n\t[string \"function train(model, criterion, batch_size, ...\"]:54: in function 'train'\n\t[string \"criterion = nn.BCECriterion()...\"]:8: in main chunk\n\t[C]: in function 'xpcall'\n\t/Users/nexus/torch/install/share/lua/5.1/itorch/main.lua:179: in function </Users/nexus/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t/Users/nexus/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/Users/nexus/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/Users/nexus/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/Users/nexus/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/Users/nexus/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t[string \"arg={'/Users/nexus/.ipython/profile_default/s...\"]:1: in main chunk"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCECriterion()\n",
    "model = get_model(150, 300, .5, 3)\n",
    "x_train, y_train, x_test, y_test = get_kth_partition(0)\n",
    "\n",
    "for e = 1, epochs do\n",
    "    print(\"training epoch \"..e)\n",
    "    -- train with batch_size = 100\n",
    "    train(model, criterion, 100, x_train, y_train)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'csvigo'\n",
    "X_csv = csvigo.load({path = \"../data/her_movie_wordvecs.csv\",\n",
    "        verbose = false, mode = \"raw\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : \n",
       "  2 : 0\n",
       "  3 : 1\n",
       "  4 : 2\n",
       "  5 : 3\n",
       "  6 : 4\n",
       "  7 : 5\n",
       "  8 : 6\n",
       "  9 : 7\n",
       "  10 : 8\n",
       "  11 : 9\n",
       "  12 : 10\n",
       "  13 : 11\n",
       "  14 : 12\n",
       "  15 : 13\n",
       "  16 : 14\n",
       "  17 : 15\n",
       "  18 : 16\n",
       "  19 : 17\n",
       "  20 : 18\n",
       "  21 : 19\n",
       "  22 : 20\n",
       "  23 : 21\n",
       "  24 : 22\n",
       "  25 : 23\n",
       "  26 : 24\n",
       "  27 : 25\n",
       "  28 : 26\n",
       "  29 : 27\n",
       "  30 : 28\n",
       "  31 : 29\n",
       "  32 : 30\n",
       "  33 : 31\n",
       "  34 : 32\n",
       "  35 : 33\n",
       "  36 : 34\n",
       "  37 : 35\n",
       "  38 : 36\n",
       "  39 : 37\n",
       "  40 : 38\n",
       "  41 : 39\n",
       "  42 : 40\n",
       "  43 : 41\n",
       "  44 : 42\n",
       "  45 : 43\n",
       "  46 : 44\n",
       "  47 : 45\n",
       "  48 : 46\n",
       "  49 : 47\n",
       "  50 : 48\n",
       "  51 : 49\n",
       "  52 : 50\n",
       "  53 : 51\n",
       "  54 : 52\n",
       "  55 : 53\n",
       "  56 : 54\n",
       "  57 : 55\n",
       "  58 : 56\n",
       "  59 : 57\n",
       "  60 : 58\n",
       "  61 : 59\n",
       "  62 : 60\n",
       "  63 : 61\n",
       "  64 : 62\n",
       "  65 : 63\n",
       "  66 : 64\n",
       "  67 : 65\n",
       "  68 : 66\n",
       "  69 : 67\n",
       "  70 : 68\n",
       "  71 : 69\n",
       "  72 : 70\n",
       "  73 : 71\n",
       "  74 : 72\n",
       "  75 : 73\n",
       "  76 : 74\n",
       "  77 : 75\n",
       "  78 : 76\n",
       "  79 : 77\n",
       "  80 : 78\n",
       "  81 : 79\n",
       "  82 : 80\n",
       "  83 : 81\n",
       "  84 : 82\n",
       "  85 : 83\n",
       "  86 : 84\n",
       "  87 : 85\n",
       "  88 : 86\n",
       "  89 : 87\n",
       "  90 : 88\n",
       "  91 : 89\n",
       "  92 : 90\n",
       "  93 : 91\n",
       "  94 : 92\n",
       "  95 : 93\n",
       "  96 : 94\n",
       "  97 : 95\n",
       "  98 : 96\n",
       "  99 : 97\n",
       "  100 : 98\n",
       "  101 : 99\n",
       "  102 : 100\n",
       "  103 : 101\n",
       "  104 : 102\n",
       "  105 : 103\n",
       "  106 : 104\n",
       "  107 : 105\n",
       "  108 : 106\n",
       "  109 : 107\n",
       "  110 : 108\n",
       "  111 : 109\n",
       "  112 : 110\n",
       "  113 : 111\n",
       "  114 : 112\n",
       "  115 : 113\n",
       "  116 : 114\n",
       "  117 : 115\n",
       "  118 : 116\n",
       "  119 : 117\n",
       "  120 : 118\n",
       "  121 : 119\n",
       "  122 : 120\n",
       "  123 : 121\n",
       "  124 : 122\n",
       "  125 : 123\n",
       "  126 : 124\n",
       "  127 : 125\n",
       "  128 : 126\n",
       "  129 : 127\n",
       "  130 : 128\n",
       "  131 : 129\n",
       "  132 : 130\n",
       "  133 : 131\n",
       "  134 : 132\n",
       "  135 : 133\n",
       "  136 : 134\n",
       "  137 : 135\n",
       "  138 : 136\n",
       "  139 : 137\n",
       "  140 : 138\n",
       "  141 : 139\n",
       "  142 : 140\n",
       "  143 : 141\n",
       "  144 : 142\n",
       "  145 : 143\n",
       "  146 : 144\n",
       "  147 : 145\n",
       "  148 : 146\n",
       "  149 : 147\n",
       "  150 : 148\n",
       "  151 : 149\n",
       "  152 : 150\n",
       "  153 : 151\n",
       "  154 : 152\n",
       "  155 : 153\n",
       "  156 : 154\n",
       "  157 : 155\n",
       "  158 : 156\n",
       "  159 : 157\n",
       "  160 : 158\n",
       "  161 : 159\n",
       "  162 : 160\n",
       "  163 : 161\n",
       "  164 : 162\n",
       "  165 : 163\n",
       "  166 : 164\n",
       "  167 : 165\n",
       "  168 : 166\n",
       "  169 : 167\n",
       "  170 : 168\n",
       "  171 : 169\n",
       "  172 : 170\n",
       "  173 : 171\n",
       "  174 : 172\n",
       "  175 : 173\n",
       "  176 : 174\n",
       "  177 : 175\n",
       "  178 : 176\n",
       "  179 : 177\n",
       "  180 : 178\n",
       "  181 : 179\n",
       "  182 : 180\n",
       "  183 : 181\n",
       "  184 : 182\n",
       "  185 : 183\n",
       "  186 : 184\n",
       "  187 : 185\n",
       "  188 : 186\n",
       "  189 : 187\n",
       "  190 : 188\n",
       "  191 : 189\n",
       "  192 : 190\n",
       "  193 : 191\n",
       "  194 : 192\n",
       "  195 : 193\n",
       "  196 : 194\n",
       "  197 : 195\n",
       "  198 : 196\n",
       "  199 : 197\n",
       "  200 : 198\n",
       "  201 : 199\n",
       "  202 : 200\n",
       "  203 : 201\n",
       "  204 : 202\n",
       "  205 : 203\n",
       "  206 : 204\n",
       "  207 : 205\n",
       "  208 : 206\n",
       "  209 : 207\n",
       "  210 : 208\n",
       "  211 : 209\n",
       "  212 : 210\n",
       "  213 : 211\n",
       "  214 : 212\n",
       "  215 : 213\n",
       "  216 : 214\n",
       "  217 : 215\n",
       "  218 : 216\n",
       "  219 : 217\n",
       "  220 : 218\n",
       "  221 : 219\n",
       "  222 : 220\n",
       "  223 : 221\n",
       "  224 : 222\n",
       "  225 : 223\n",
       "  226 : 224\n",
       "  227 : 225\n",
       "  228 : 226\n",
       "  229 : 227\n",
       "  230 : 228\n",
       "  231 : 229\n",
       "  232 : 230\n",
       "  233 : 231\n",
       "  234 : 232\n",
       "  235 : 233\n",
       "  236 : 234\n",
       "  237 : 235\n",
       "  238 : 236\n",
       "  239 : 237\n",
       "  240 : 238\n",
       "  241 : 239\n",
       "  242 : 240\n",
       "  243 : 241\n",
       "  244 : 242\n",
       "  245 : 243\n",
       "  246 : 244\n",
       "  247 : 245\n",
       "  248 : 246\n",
       "  249 : 247\n",
       "  250 : 248\n",
       "  251 : 249\n",
       "  252 : 250\n",
       "  253 : 251\n",
       "  254 : 252\n",
       "  255 : 253\n",
       "  256 : 254\n",
       "  257 : 255\n",
       "  258 : 256\n",
       "  259 : 257\n",
       "  260 : 258\n",
       "  261 : 259\n",
       "  262 : 260\n",
       "  263 : 261\n",
       "  264 : 262\n",
       "  265 : 263\n",
       "  266 : 264\n",
       "  267 : 265\n",
       "  268 : 266\n",
       "  269 : 267\n",
       "  270 : 268\n",
       "  271 : 269\n",
       "  272 : 270\n",
       "  273 : 271\n",
       "  274 : 272\n",
       "  275 : 273\n",
       "  276 : 274\n",
       "  277 : 275\n",
       "  278 : 276\n",
       "  279 : 277\n",
       "  280 : 278\n",
       "  281 : 279\n",
       "  282 : 280\n",
       "  283 : 281\n",
       "  284 : 282\n",
       "  285 : 283\n",
       "  286 : 284\n",
       "  287 : 285\n",
       "  288 : 286\n",
       "  289 : 287\n",
       "  290 : 288\n",
       "  291 : 289\n",
       "  292 : 290\n",
       "  293 : 291\n",
       "  294 : 292\n",
       "  295 : 293\n",
       "  296 : 294\n",
       "  297 : 295\n",
       "  298 : 296\n",
       "  299 : 297\n",
       "  300 : 298\n",
       "  301 : 299\n",
       "}\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.remove(X_csv, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#X_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#(X_csv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = copy_example(torch.Tensor(X_csv)[{{1,146}, {2, 301}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.5382  0.5065  0.5965  0.4645  0.4893  0.5579  0.4914  0.4320\n",
       "[torch.DoubleTensor of size 1x8]\n",
       "\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model:forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
