{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "# from sklearn.multiclass import LabelPowerSetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are the metrics we want to use for evaluation\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# actual estimators\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMETRICS = {\\n    \"hamming_loss\": hamming_loss,\\n    \"subset_accuracy\": accuracy_score,\\n    \"precision\": precision_score,\\n    \"macro-f1\": partial(f1_score, average=\"macro\"),\\n    \"micro-f1\": partial(f1_score, average=\"micro\"),\\n}\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scoring metrics used for evaluation. namely precision, accuracy, hamming loss (recall)\n",
    "# and f_1-score with several different averages\n",
    "METRICS = ['precision_macro', 'recall_macro', 'f1_macro', 'precision_micro', 'recall_micro', 'f1_micro']\n",
    "\n",
    "\"\"\"\n",
    "METRICS = {\n",
    "    \"hamming_loss\": hamming_loss,\n",
    "    \"subset_accuracy\": accuracy_score,\n",
    "    \"precision\": precision_score,\n",
    "    \"macro-f1\": partial(f1_score, average=\"macro\"),\n",
    "    \"micro-f1\": partial(f1_score, average=\"micro\"),\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/atmosphere_train.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading the already trained word embedding model\n",
    "model = Word2Vec.load(\"../prep/200features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $j$-th component of the label vector is $1$ if the $j$-th label value is greater or equal to three. $0$ is used otherwise.\n",
    "\n",
    "$v_{ij} = I[l_{ij} \\geq 3]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_wordlist(text, remove_stops=False):\n",
    "    \"\"\"\n",
    "    Function that cleans the movie description text. Removes\n",
    "    non-alphabetical letters and optionally english stop words.\n",
    "    \"\"\"\n",
    "    # first step is to remove non-alphabetical characters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    \n",
    "    words = text.lower().split()\n",
    "    \n",
    "    if remove_stops:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        return [w for w in words if not w in stops]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_vec(words, f_size, model):\n",
    "    n = .0\n",
    "    x_i = np.zeros(f_size, dtype=\"float32\")\n",
    "    \n",
    "    # internal word list of word2vec\n",
    "    idx2words = set(model.index2word)\n",
    "    \n",
    "    s = filter(lambda e: e in idx2words, words)\n",
    "\n",
    "    for w in s:\n",
    "        n += 1.\n",
    "        x_i = np.add(x_i, model[w])\n",
    "    \n",
    "    return np.divide(x_i, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def raw_row_to_X_y(row, f_size, model):\n",
    "    \"\"\"\n",
    "    Outputs tuple for an instance containing of the (Xi, yi) feature vector/label vector pair.\n",
    "    The label vector is given by the equation above.\n",
    "    \"\"\"\n",
    "    \n",
    "    # prepare the labels\n",
    "    labels = row[\"labels\"].split(\",\")\n",
    "\n",
    "    y = [\n",
    "        int(\"atmosphere_food_for_thought\" in labels),\n",
    "        int(\"atmosphere_funny\" in labels),\n",
    "        int(\"atmosphere_action\" in labels),\n",
    "        int(\"atmosphere_emotional\" in labels),\n",
    "        int(\"atmosphere_romantic\" in labels),\n",
    "        int(\"atmosphere_dark\" in labels),\n",
    "        int(\"atmosphere_brutal\" in labels),\n",
    "        int(\"atmosphere_thrilling\" in labels)\n",
    "    ]\n",
    "    \n",
    "    # create feature vector with word2vec model\n",
    "    X = get_feature_vec(make_wordlist(row[\"descr\"]), f_size, model)\n",
    "    \n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, movie in test_data.iterrows():\n",
    "    if idx > 1:# and idx < 50:\n",
    "        t = raw_row_to_X_y(movie, 200, model)\n",
    "        X.append(t[0])\n",
    "        y.append(t[1])\n",
    "\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(e, X, y):\n",
    "    \"\"\"\n",
    "    Train all the estimators on the current dataset.\n",
    "    The fit method should reset internals anyway.\n",
    "    \"\"\"\n",
    "    e.fit(X, y)\n",
    "        \n",
    "\n",
    "def test(e, X, y):\n",
    "    # calculating metrics based on the training set\n",
    "    for metric in METRICS:\n",
    "        scores = cross_validation.cross_val_score(e, X, y, cv=10, scoring=metric)\n",
    "\n",
    "        print \"\\t\\tmean %s: %s\" % (metric, scores.sum() / len(scores))\n",
    "\n",
    "\n",
    "def run_est(X, y):\n",
    "    \"\"\"\n",
    "    Prepare, train and test the estimators on the given dataset.\n",
    "    \"\"\"\n",
    "    tic = time.time()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y,\n",
    "                                            test_size=0.1, random_state=0)\n",
    "\n",
    "    # all means of given METRICS\n",
    "    means = []\n",
    "\n",
    "    for e_name, e in ESTIMATORS.items():\n",
    "        # create new estimator with equivalent parameters as the current one\n",
    "        e_ = e # .clone() FIXME: clone the classifier?\n",
    "\n",
    "        print \"\\t-> training + testing \", e_name\n",
    "\n",
    "        train(e_, X_train, y_train)\n",
    "        print \"\\t-> %ds elapsed for training\" % (time.time() - tic,)\n",
    "\n",
    "        ms = test(e_, X_test, y_test)\n",
    "        print \"\\t-> %ds elapsed for testing\" % (time.time() - tic,)\n",
    "\n",
    "        means.append(ms)\n",
    "\n",
    "    return (X_train, y_train, X_test, y_test, means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ESTIMATORS = {\n",
    "    \"OVR Random Forest\": OneVsRestClassifier(RandomForestClassifier(n_estimators = 100)),\n",
    "    \"OVR LinearSVC\": OneVsRestClassifier(LinearSVC(random_state=1)),\n",
    "    \"OVR Gaussian Naive Bayes\": OneVsRestClassifier(GaussianNB()),\n",
    "    \"OVR Bernoulli Naive Bayes\": OneVsRestClassifier(BernoulliNB()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-> training + testing  OVR Gaussian Naive Bayes\n",
      "\t-> 0s elapsed for training\n",
      "\t\tmean precision_macro: 0.710877334471\n",
      "\t\tmean recall_macro: 0.636445378667\n",
      "\t\tmean f1_macro: 0.656347760863\n",
      "\t\tmean precision_micro: 0.723994611371\n",
      "\t\tmean recall_micro: 0.647858788645\n",
      "\t\tmean f1_micro: 0.680624210158\n",
      "\t-> 1s elapsed for testing\n",
      "\t-> training + testing  OVR LinearSVC\n",
      "\t-> 1s elapsed for training\n",
      "\t\tmean precision_macro: 0.70814716657\n",
      "\t\tmean recall_macro: 0.704340730541\n",
      "\t\tmean f1_macro: 0.679625088525\n",
      "\t\tmean precision_micro: 0.71852231449\n",
      "\t\tmean recall_micro: 0.752661325719\n",
      "\t\tmean f1_micro: 0.733229381496\n",
      "\t-> 5s elapsed for testing\n",
      "\t-> training + testing  OVR Random Forest\n",
      "\t-> 18s elapsed for training\n",
      "\t\tmean precision_macro: 0.681784115223\n",
      "\t\tmean recall_macro: 0.717555665654\n",
      "\t\tmean f1_macro: 0.693270063145"
     ]
    }
   ],
   "source": [
    "data = run_est(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_for_thought, funny, action, emotional, romantic, dark, brutal, thrilling\n",
      "OVR Gaussian Naive Bayes :  [0 1 0 1 1 0 0 0]\n",
      "OVR LinearSVC :  [1 1 0 1 1 0 0 1]\n",
      "OVR Random Forest :  [1 1 0 1 1 0 0 1]\n",
      "OVR Bernoulli Naive Bayes :  [0 1 0 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# let's test an actual movie!\n",
    "plot = \"\"\"Theodore is a lonely man in the final stages of his divorce. When he's not working as a letter writer, his down time is spent playing video games and occasionally hanging out with friends. He decides to purchase the new OS1, which is advertised as the world's first artificially intelligent operating system, \"It's not just an operating system, it's a consciousness,\" the ad states. Theodore quickly finds himself drawn in with Samantha, the voice behind his OS1. As they start spending time together they grow closer and closer and eventually find themselves in love. Having fallen in love with his OS, Theodore finds himself dealing with feelings of both great joy and doubt. As an OS, Samantha has powerful intelligence that she uses to help Theodore in ways others hadn't, but how does she help him deal with his inner conflict of being in love with an OS?\"\"\"\n",
    "X_i = get_feature_vec(make_wordlist(plot), 200, model)\n",
    "\n",
    "print \"food_for_thought, funny, action, emotional, romantic, dark, brutal, thrilling\"\n",
    "for e_name, e in ESTIMATORS.items():\n",
    "    y_pred = e.predict(X_i.reshape(1, -1))\n",
    "    print e_name, \": \", y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_for_thought, funny, action, emotional, romantic, dark, brutal, thrilling\n",
      "OVR Gaussian Naive Bayes :  [0 1 0 0 0 0 0 0]\n",
      "OVR LinearSVC :  [1 1 1 1 0 0 0 1]\n",
      "OVR Random Forest :  [1 1 1 1 0 0 0 1]\n",
      "OVR Bernoulli Naive Bayes :  [0 1 0 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "plot = \"\"\"In Paris, the aristocratic and intellectual Philippe is a quadriplegic millionaire who is interviewing candidates for the position of his carer, with his red-haired secretary Magalie. Out of the blue, the rude African Driss cuts the line of candidates and brings a document from the Social Security and asks Phillipe to sign it to prove that he is seeking a job position so he can receive his unemployment benefit. Philippe challenges Driss, offering him a trial period of one month to gain experience helping him. Then Driss can decide whether he would like to stay with him or not. Driss accepts the challenge and moves to the mansion, changing the boring life of Phillipe and his employees.\"\"\"\n",
    "X_i = get_feature_vec(make_wordlist(plot), 200, model)\n",
    "\n",
    "print \"food_for_thought, funny, action, emotional, romantic, dark, brutal, thrilling\"\n",
    "for e_name, e in ESTIMATORS.items():\n",
    "    y_pred = e.predict(X_i.reshape(1, -1))\n",
    "    print e_name, \": \", y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
